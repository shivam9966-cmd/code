# ============================================================
# Rebuild consolidated dataset + include extra hierarchy cols
# Filter to the ~5k least-frequent accounts (include full last)
# Keep ONLY requested columns (from your screenshot)
# ============================================================

from pyspark.sql import functions as F, Window

# ---------- Load facts & dimensions ----------
actual_df   = spark.table("FPNA_FISRPT_SILVER.dbo.ACTUALS")
plan_df     = spark.table("FPNA_FISRPT_SILVER.dbo.PLAN")
forecast_df = spark.table("FPNA_FISRPT_SILVER.dbo.FORECAST")

account_df    = spark.table("FPNA_FISRPT_SILVER.dbo.account").alias("ad")
product_df    = spark.table("FPNA_FISRPT_SILVER.dbo.product").alias("pd")
costcenter_df = spark.table("FPNA_FISRPT_SILVER.dbo.cost_center").alias("cc")

# ---------- Helper: safely pick/rename dim columns ----------
def safe_dim_cols(df_alias, wanted, out_prefix, existing):
    """
    wanted: list[(source_col_name, output_suffix_name)]
    out name = f"{out_prefix}{output_suffix}"
    """
    cols = []
    for src, suffix in wanted:
        out_name = f"{out_prefix}{suffix}"
        if src in existing:
            cols.append(F.col(f"{df_alias}.{src}").alias(out_name))
        else:
            cols.append(F.lit(None).cast("string").alias(out_name))
    return cols

acc_exist = set(account_df.columns)
pd_exist  = set(product_df.columns)
cc_exist  = set(costcenter_df.columns)

# Map the *actual* dimension column names on your tables to the output names you want.
ACC_WANTED = [
    ("Account",        "Code"),            # -> account_Code (not selected in final, used for joins/option)
    ("L4",             "L4"),              # -> account_L4
    ("L5_Description", "L5_Description"),  # -> account_L5_Description
    ("L6_Description", "L6_Description"),  # -> account_L6_Description
    ("L7_Description", "L7_Description"),  # -> account_L7_Description
]

PD_WANTED = [
    ("L3_Description", "L3_Description"),  # -> product_L3_Description
    ("L4_Description", "L4_Description"),  # -> product_L4_Description
    ("L5_Description", "L5_Description"),  # -> product_L5_Description
    ("L6_Description", "L6_Description"),  # -> product_L6_Description
    ("L7_Description", "L7_Description"),  # -> product_L7_Description
    ("L8_Description", "L8_Description"),  # -> product_L8_Description
]

CC_WANTED = [
    ("CC_L1_Description", "L1_Description"),  # -> CC_L1_Description
    ("CC_L2_Description", "L2_Description"),  # -> CC_L2_Description
    ("CC_L3_Description", "L3_Description"),  # -> CC_L3_Description
    ("CC_L4_Description", "L4_Description"),  # -> CC_L4_Description
]

# ---------- Build per-fact: join dims + KPI filter + select ----------
def prepare_fact(df, source_name):
    d = df.alias("d")
    j = (
        d.join(account_df,    F.col("d.ACCOUNT")     == F.col("ad.Account"),     "left")
         .join(product_df,    F.col("d.PRODUCTLINE") == F.col("pd.ProductLine"), "left")
         .join(costcenter_df, F.col("d.COSTCENTER")  == F.col("cc.COSTCENTER"),  "left")
    )

    # KPI tagging & filter
    j = j.withColumn(
        "KPI",
        F.when(F.col("ad.L5_Description") == "Revenue", "Revenue")
         .when(F.col("ad.L5_Description") == "Operating Expenses", "OPEX")
         .when(F.col("ad.L4") == "EBITDA", "EBITDA")
    ).filter(F.col("KPI").isNotNull())

    # Fact columns (as-is)
    fact_cols = [F.col(f"d.{c}").alias(c) for c in df.columns]

    # Dim columns (expanded)
    acc_cols = safe_dim_cols("ad", ACC_WANTED, "account_", acc_exist)
    pd_cols  = safe_dim_cols("pd", PD_WANTED, "product_", pd_exist)
    cc_cols  = safe_dim_cols("cc", CC_WANTED, "CC_", cc_exist)

    return j.select(
        *fact_cols, *acc_cols, *pd_cols, *cc_cols,
        F.col("KPI"),
        F.lit(source_name).alias("FACT_SOURCE")
    )

# ---------- Build consolidated (same as before, but with extra dim cols) ----------
act_kpi  = prepare_fact(actual_df,   "ACTUALS")
plan_kpi = prepare_fact(plan_df,     "PLAN")
fcst_kpi = prepare_fact(forecast_df, "FORECAST")

granular = (act_kpi
            .unionByName(plan_kpi, allowMissingColumns=True)
            .unionByName(fcst_kpi, allowMissingColumns=True))

# ---------- Accounts by ascending frequency; include full last over target ----------
ACCOUNT_COL = "ACCOUNT"   # change if your column is named differently
TARGET = 5000

acct_counts = (granular.groupBy(ACCOUNT_COL).count()
               .orderBy(F.col("count").asc(), F.col(ACCOUNT_COL).asc()))

w = Window.orderBy(F.col("count").asc(), F.col(ACCOUNT_COL).asc())
acct_counts = (acct_counts
               .withColumn("row_number",   F.row_number().over(w))
               .withColumn("cumulative_sum", F.sum("count").over(w)))

exceed = (acct_counts.filter(F.col("cumulative_sum") > TARGET)
                    .orderBy("cumulative_sum")
                    .select("row_number")
                    .limit(1)
                    .collect())

if exceed:
    rnum = exceed[0][0]
    chosen_accts = (acct_counts
                    .where((F.col("cumulative_sum") <= TARGET) | (F.col("row_number") == rnum))
                    .select(ACCOUNT_COL).distinct())
else:
    chosen_accts = acct_counts.select(ACCOUNT_COL).distinct()

subset = granular.join(chosen_accts, on=ACCOUNT_COL, how="inner")

# ---------- Keep EXACTLY the columns from your screenshot ----------
REQUESTED_COLS = [
    "product_L3_Description",
    "product_L4_Description",
    "product_L5_Description",
    "product_L6_Description",
    "product_L7_Description",
    "product_L8_Description",
    "account_L5_Description",
    "account_L6_Description",
    "account_L7_Description",
    "CC_L1_Description",
    "CC_L2_Description",
    "CC_L3_Description",
    "CC_L4_Description",
    "ACCOUNT",
    "COSTCENTER",
    "PRODUCTLINE",
    "SCENARIO",
    "VERSION",
    "Amount",
    "YEAR",
    "QUARTER"
]

# Build a case-insensitive selector against current columns
available = {c.lower(): c for c in subset.columns}
keep_cols = [available[c.lower()] for c in REQUESTED_COLS if c.lower() in available]
missing   = [c for c in REQUESTED_COLS if c.lower() not in available]

if missing:
    print("[INFO] These requested columns were NOT found (case-insensitive):", missing)

subset = subset.select(*keep_cols)

# ---------- Report & preview (no save) ----------
print(f"âœ… Final subset rows (including full last account): {subset.count():,}")
print("\nIncluded accounts (first 50, ascending by count):")
(acct_counts
 .join(chosen_accts, on=ACCOUNT_COL, how="inner")
 .orderBy(F.col("count").asc(), F.col(ACCOUNT_COL).asc())
 .select(ACCOUNT_COL, "count", "cumulative_sum")
 .show(50, truncate=False))

print("\nPreview (first 20 rows):")
subset.show(20, truncate=False)
# display(subset.limit(20))  # If you prefer table UI in Fabric/Synapse
