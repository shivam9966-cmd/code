# ================================================================
# VALIDATION OF ANOMALIES (Cross-check correctness)
# ================================================================
from pyspark.sql import functions as F, Window as W

# Choose which KPI to validate
KPI_TO_VALIDATE = "EBITDA"   # change to "OPEX" or "Revenue" as needed

# Filter anomalies of that KPI
anoms_to_validate = combined_anoms.filter(F.col("aan_name") == KPI_TO_VALIDATE)

# Join anomalies back with original data to get actual value
kpi_df = df.filter(F.col("account_L5_Description") == F.lit(KPI_TO_VALIDATE))

# Recreate grouping window (same as anomaly detection)
group_cols = ACCOUNT_LEVELS + PRODUCT_LEVELS + COSTCENTER_LEVELS
hist_w = (
    W.partitionBy(*group_cols)
     .orderBy(F.col("pred_date"))
     .rowsBetween(-14, -1)
)

kpi_df = (
    kpi_df
    .withColumn("rolling_mean", F.avg("Amount").over(hist_w))
    .withColumn("rolling_std",  F.stddev_samp("Amount").over(hist_w))
    .withColumn("lower_band",   F.col("rolling_mean") - 3 * F.col("rolling_std"))
    .withColumn("upper_band",   F.col("rolling_mean") + 3 * F.col("rolling_std"))
)

# Join to anomalies on full hierarchy + date
join_keys = group_cols + ["pred_date"]
validation_df = (
    anoms_to_validate.alias("a")
    .join(kpi_df.alias("k"), join_keys, "left")
    .select(
        "a.*",
        F.col("k.Amount").alias("actual_value"),
        "k.rolling_mean",
        "k.rolling_std",
        "k.lower_band",
        "k.upper_band"
    )
    .withColumn("recomputed_delta",
                ((F.col("actual_value") - F.col("rolling_mean")) / F.col("rolling_mean")) * 100)
    .withColumn("delta_diff", F.round(F.col("recomputed_delta") - F.col("aan_delta").cast("double"), 2))
    .withColumn("is_outside_band",
                (F.col("actual_value") < F.col("lower_band")) | (F.col("actual_value") > F.col("upper_band")))
)

display(validation_df.select(
    "aan_name", "predictive_date", "aan_level", "aan_value",
    "actual_value", "rolling_mean", "rolling_std",
    "lower_band", "upper_band", "aan_delta", "recomputed_delta", "delta_diff", "is_outside_band"
).orderBy(F.col("predictive_date").desc()))
