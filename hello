tmp_path = "Files/SQL_TMP/final_csv"
df_final.write.mode("overwrite").option("header", True).csv(tmp_path)
print("CSV saved at:", tmp_path)




import glob

# Folder where SQL dump will be saved
output_path = "Files/SQL_DUMPS/FINAL_EXPORTS/final_dump.sql"

# All csv part files
csv_files = glob.glob("/lakehouse/default/" + tmp_path + "/*.csv")

# Read header from first CSV
with open(csv_files[0], "r", encoding="utf-8") as f:
    header = f.readline().strip().split(",")

table_name = "your_table_name"

with open("/lakehouse/default/" + output_path, "w", encoding="utf-8") as sql_out:
    for file in csv_files:
        with open(file, "r", encoding="utf-8") as f:
            f.readline()  # skip header
            for line in f:
                values = line.strip().split(",")
                escaped = ["'" + v.replace("'", "''") + "'" for v in values]

                sql_out.write(
                    f"INSERT INTO {table_name} ({','.join(header)}) "
                    f"VALUES ({','.join(escaped)});\n"
                )

print("SQL dump created at:", output_path)
