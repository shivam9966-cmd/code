df_single = (
    spark.read
    .option("header", True)
    .csv("Files/SQL_DUMPS/FINAL_EXPORTS/Run_2025-11-10_09-11-55/granular_subset_single/*")
)

df_single.count()
