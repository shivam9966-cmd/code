saved_df = spark.read.csv("Files/SQL_DUMPS_SMALL_ACCOUNTS", header=True, inferSchema=True)

row_count = saved_df.count()
print(f"âœ… Total rows in saved CSV file: {row_count:,}")
