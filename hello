rename_map = {
    "ACCOUNT": "account",
    "COSTCENTER": "costcenter",
    "CURRENCY": "currency",
    "CUSTOMER": "customer",
    "DATASOURCE": "datasource",
    "ENTITY": "entity",
    "ICP": "icp",
    "LOCATION": "location",
    "PRODUCTLINE": "productline",
    "SCENARIO": "scenario",
    "VERSION": "version",
    "VIEW": "view",
    "YEAR": "year",
    "PERIOD": "period",
    "Amount": "amount",
    "DATE": "date",
    "QUARTER": "quarter",
    "COSTCENTER_PRODUCTLINE": "costcenter_productline",
    "CC_PR_AC": "cc_pr_ac",
    "Account_Code": "account_code",
    "Account_L4": "account_L4",
    "Account_L5_Description": "account_L5_Description",
    "Product_Line": "product_line",
    "Product_L3_Description": "product_L3_Description",
    "Cost_Center_Code": "cost_center_code",
    "Cost_Center_L3_Description": "cost_center_L3_Description",
    "KPI": "kpi",
    "FACT_SOURCE": "fact_source",
    "Actual": "actual_months",
    "Forecasted": "forecasted_months"
}







df_final = df_filtered

for old, new in rename_map.items():
    if old in df_final.columns:
        df_final = df_final.withColumnRenamed(old, new)






from pyspark.sql import functions as F

df_final = df_final.withColumn("date", F.to_date("date"))

df_final = df_final.withColumn(
    "actual_months",
    F.coalesce("actual_months", F.lit(0))
)

df_final = df_final.withColumn(
    "forecasted_months",
    F.coalesce("forecasted_months", F.lit(0))
)
