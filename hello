# ============================================
# Concatenate ACTUALS + PLAN + FORECAST
# Dedupe rule (per table): if ONLY Amount differs -> sum Amount; else keep rows separate
# Save to Files/SQL_DUMPS
# ============================================

import pyspark.sql.functions as F

# --------- Config ---------
TARGET_PATH = "/lakehouse/default/Files/SQL_DUMPS/FACTS_CONCAT_DEDUP"  # folder will be (over)written
OUTPUT_FORMAT = "parquet"  # "parquet" | "delta" | "csv"
COALESCE_SINGLE_FILE = True

# --------- Load the fact tables ---------
actual_df   = spark.table("FPNA_FISRPT_SILVER.dbo.ACTUALS")
plan_df     = spark.table("FPNA_FISRPT_SILVER.dbo.PLAN")
forecast_df = spark.table("FPNA_FISRPT_SILVER.dbo.FORECAST")

# --------- Helper: find the Amount column case-insensitively ---------
def find_amount_col(df):
    for c in df.columns:
        if c.lower() == "amount":
            return c
    raise ValueError("No 'Amount' column found (case-insensitive) in dataframe.")

# --------- Helper: dedupe per-table by summing Amount when only Amount differs ---------
def dedupe_sum_amount(df):
    amt_col = find_amount_col(df)
    key_cols = [c for c in df.columns if c != amt_col]
    return df.groupBy(key_cols).agg(F.sum(F.col(amt_col)).alias(amt_col))

# --------- Dedupe each fact ---------
actual_d  = dedupe_sum_amount(actual_df)
plan_d    = dedupe_sum_amount(plan_df)
forecast_d= dedupe_sum_amount(forecast_df)

# --------- Align schemas by column NAME (order can differ) ---------
# If there are any accidental column diffs, fill missing with NULL so unionByName works safely.
def align_to_columns(df, target_cols):
    cols_df = set(df.columns)
    # select existing columns in target order, add NULL for missing
    selected = [F.col(c) if c in cols_df else F.lit(None).alias(c) for c in target_cols]
    return df.select(*selected)

# Use ACTUALS as the "master" column list (you said all three have same columns, just different order)
master_cols = actual_d.columns
plan_d_aligned     = align_to_columns(plan_d, master_cols)
forecast_d_aligned = align_to_columns(forecast_d, master_cols)

# --------- Concatenate (stack) all three ---------
facts_concat = (
    actual_d
      .unionByName(plan_d_aligned, allowMissingColumns=True)
      .unionByName(forecast_d_aligned, allowMissingColumns=True)
)

# --------- Save to Files/SQL_DUMPS ---------
writer = facts_concat
if COALESCE_SINGLE_FILE and OUTPUT_FORMAT in ("parquet","csv"):
    writer = writer.coalesce(1)

writer = writer.write.mode("overwrite")

if OUTPUT_FORMAT == "csv":
    (writer.format("csv").option("header","true").save(TARGET_PATH))
elif OUTPUT_FORMAT == "delta":
    (writer.format("delta").option("overwriteSchema","true").save(TARGET_PATH))
else:  # parquet (default)
    (writer.format("parquet").save(TARGET_PATH))

print(f"[OK] Concatenated, deduped facts saved at: {TARGET_PATH} (format={OUTPUT_FORMAT})")
