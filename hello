df = spark.read.parquet("Files/SQL_DUMPS/FACTS_CONCAT_DEDUP_JOINED_KPI")
print(df.columns)

df = spark.read.option("header", "true").csv("Files/SQL_DUMPS/FACTS_CONCAT_DEDUP_JOINED_KPI")
print(df.columns)


df = spark.read.parquet("Files/SQL_DUMPS/FACTS_CONCAT_DEDUP_JOINED_KPI")
df.show(20, truncate=False)







print("Row count:", df_final.count())
print("Columns:", df_final.columns)


df_final.groupBy("FACT_SOURCE").count().show()


df_final.select("KPI", "FACT_SOURCE", "Amount").distinct().show(20)


(
    df_final.groupBy([c for c in df_final.columns if c != "Amount"])
    .count()
    .filter("count > 1")
    .show(20, truncate=False)
)
