import pandas as pd
import json
from llama_index.llms.azure_openai import AzureOpenAI
from llama_index.core import Settings


llm = AzureOpenAI(
    model="gpt-4o-mini",
    deployment_name="XXX",          # your deployment
    api_key="XXX",                  # your key
    azure_endpoint="XXX",           # your endpoint
    api_version="XXX",              # your version
    max_tokens=2000,
    temperature=0.2
)

Settings.llm = llm

SUMMARY_PROMPT = """
You are an FP&A analytics expert.

You will be given JSON data for a specific financial category at the level: "{level}".
Summarize ONLY the given category.

STRICT RULE:
- If level = "Revenue": DO NOT mention OPEX or EBITDA.
- If level = "OPEX": DO NOT mention Revenue or EBITDA.
- If level = "EBITDA": DO NOT mention Revenue or OPEX.

Your task is to produce a clean JSON summary containing:
1. executive_summary ‚Üí 4‚Äì6 short bullet points (max 20 words each)
2. usd_values ‚Üí JSON listing key USD metrics extracted or calculated from JSON input
3. variance_percent ‚Üí percent change from first month to last month
4. top_drivers ‚Üí list of bullet points describing primary drivers
5. risks_and_opportunities ‚Üí bullet points listing risks & opportunities
6. areas_of_focus ‚Üí 2‚Äì4 tactical recommendations

Formatting rules:
- Use emojis for indicators:
  üìà increase
  üìâ decrease
  ‚ö†Ô∏è risk
  ‚≠ê positive
- No nested JSON inside fields.
- No commentary outside JSON.

Return strictly:

{
  "level": "",
  "executive_summary": [],
  "usd_values": {},
  "variance_percent": "",
  "top_drivers": [],
  "risks_and_opportunities": [],
  "areas_of_focus": []
}
"""


def normalize_value(x):
    return str(x).strip() if x is not None else None


def compute_variance(records):
    if not records or len(records) < 2:
        return 0.0
    first = records[0]["amount"]
    last = records[-1]["amount"]
    if first == 0:
        return 0.0
    return round(((last - first) / first) * 100, 2)


def aggregate_by_level(df, bucket_name, bucket_col, level_col, date_col, amount_col):
    sub = df[df[bucket_col] == bucket_name]
    if sub.empty:
        return {}

    grouped = (
        sub.groupby([level_col, date_col])[amount_col]
        .sum()
        .reset_index()
        .sort_values([level_col, date_col])
    )

    output = {}
    for level_value, grp in grouped.groupby(level_col):
        rows = []
        for _, row in grp.iterrows():
            rows.append({
                "amount": float(row[amount_col]),
                "ending_date_of_month": row[date_col].strftime("%Y-%m-%d")
            })
        output[level_value] = rows

    return output


def top_n_categories(cat_dict, n=3):
    totals = {k: sum(item["amount"] for item in v) for k, v in cat_dict.items()}
    top_keys = sorted(totals, key=totals.get, reverse=True)[:n]
    return {k: cat_dict[k] for k in top_keys}


def generate_usecases(
    df,
    year,
    months,
    level="L6",
    date_col="DATE",
    amount_col="AMOUNT",
    bucket_col="account_L5_Description"
):
    LEVEL_MAP = {
        "L6": "account_L6_Description",
        "L7": "account_L7_Description"
    }

    level_col = LEVEL_MAP[level]

    df = df.copy()
    df[level_col] = df[level_col].apply(normalize_value)
    df[date_col] = pd.to_datetime(df[date_col])

    df_filtered = df[
        (df[date_col].dt.year == year) &
        (df[date_col].dt.month.isin(months))
    ].copy()

    usecases = {}

    # -------------------- Revenue --------------------
    revenue_dict = aggregate_by_level(
        df_filtered, "Revenue", bucket_col, level_col, date_col, amount_col
    )

    revenue_final = {
        k: {
            "values": v,
            "variance_percent": compute_variance(v)
        }
        for k, v in revenue_dict.items()
    }

    usecases["Revenue"] = revenue_final

    # --------------------- OPEX ----------------------
    opex_dict = aggregate_by_level(
        df_filtered, "Operating Expenses", bucket_col, level_col, date_col, amount_col
    )

    opex_top3 = top_n_categories(opex_dict, n=3)

    opex_final = {
        k: {
            "values": v,
            "variance_percent": compute_variance(v)
        }
        for k, v in opex_top3.items()
    }

    usecases["OPEX"] = opex_final

    # --------------------- EBITDA --------------------
    rev_monthly = (
        df_filtered[df_filtered[bucket_col] == "Revenue"]
        .groupby(date_col)[amount_col].sum()
        .reset_index()
    )

    opex_monthly = (
        df_filtered[df_filtered[bucket_col] == "Operating Expenses"]
        .groupby(date_col)[amount_col].sum()
        .reset_index()
    )

    rev_map = {r[date_col].strftime("%Y-%m-%d"): float(r[amount_col]) for _, r in rev_monthly.iterrows()}
    opex_map = {r[date_col].strftime("%Y-%m-%d"): float(r[amount_col]) for _, r in opex_monthly.iterrows()}

    common_dates = sorted(set(rev_map.keys()) & set(opex_map.keys()))

    ebitda_records = []
    for d in common_dates:
        ebitda_records.append({
            "amount": rev_map[d] - opex_map[d],
            "ending_date_of_month": d
        })

    usecases["EBITDA"] = {
        "ebitda": ebitda_records,
        "variance_percent": compute_variance(ebitda_records)
    }

    return usecases



def summarize_one_level(level_name, data_dict):
    prompt = SUMMARY_PROMPT.format(level=level_name)
    final_prompt = f"{prompt}\n\nHere is the JSON data:\n{json.dumps(data_dict, indent=2)}"

    response = llm.complete(final_prompt)

    try:
        return json.loads(response.text)
    except:
        return {"error": "Invalid JSON returned", "raw": response.text}


def generate_llm_summary(usecases):
    summary = {}
    for lvl in ["Revenue", "OPEX", "EBITDA"]:
        if lvl in usecases:
            summary[lvl] = summarize_one_level(lvl, usecases[lvl])
    return summary


def generate_business_summary(df, year, months, level="L6"):
    usecases = generate_usecases(df, year, months, level=level)
    summary = generate_llm_summary(usecases)
    return summary
