
import pandas as pd

# Load your granular file
df = pd.read_csv("granular_subset_single.csv")

# Set column names
DATE_COL   = "DATE"                     # <-- your real date column
AMOUNT_COL = "AMOUNT"
BUCKET_COL = "account_L5_Description"   # "Revenue" / "Operating Expenses"
L6_COL     = "account_L6_Description"   # breakdown level


df[DATE_COL] = pd.to_datetime(df[DATE_COL])

TARGET_YEAR   = 2025
TARGET_MONTHS = [6, 7, 8]   # change if needed

df_filtered = df[
    (df[DATE_COL].dt.year == TARGET_YEAR) &
    (df[DATE_COL].dt.month.isin(TARGET_MONTHS))
].copy()



def aggregate_l6(df, bucket_name):
    """
    Returns:
    {
       'L6 category 1': [ {amount, ending_date_of_month}, ... ],
       'L6 category 2': [ ... ],
       ...
    }
    """
    sub = df[df[BUCKET_COL] == bucket_name]
    if sub.empty:
        return {}

    grouped = (
        sub.groupby([L6_COL, DATE_COL])[AMOUNT_COL]
           .sum()
           .reset_index()
           .sort_values([L6_COL, DATE_COL])
    )

    out = {}
    for l6, grp in grouped.groupby(L6_COL):
        rows = []
        for _, row in grp.iterrows():
            rows.append({
                "amount": float(row[AMOUNT_COL]),
                "ending_date_of_month": row[DATE_COL].strftime("%Y-%m-%d")
            })
        out[l6] = rows

    return out



def top_n_l6(l6_dict, n=3):
    totals = {k: sum(item["amount"] for item in v) for k, v in l6_dict.items()}
    top_keys = sorted(totals, key=totals.get, reverse=True)[:n]
    return {k: l6_dict[k] for k in top_keys}



def build_usecases_from_df(df):

    # L6-level breakdowns
    revenue_l6 = aggregate_l6(df, "Revenue")
    opex_l6_all = aggregate_l6(df, "Operating Expenses")
    
    # Keep only top 3 OPEX L6 categories
    opex_l6_top3 = top_n_l6(opex_l6_all, n=3)

    # Monthly totals (for EBITDA)
    rev_monthly = (
        df[df[BUCKET_COL] == "Revenue"]
        .groupby(DATE_COL)[AMOUNT_COL]
        .sum()
        .reset_index()
    )

    opex_monthly = (
        df[df[BUCKET_COL] == "Operating Expenses"]
        .groupby(DATE_COL)[AMOUNT_COL]
        .sum()
        .reset_index()
    )

    rev_map = {row[DATE_COL].strftime("%Y-%m-%d"): float(row[AMOUNT_COL]) for _, row in rev_monthly.iterrows()}
    opex_map = {row[DATE_COL].strftime("%Y-%m-%d"): float(row[AMOUNT_COL]) for _, row in opex_monthly.iterrows()}

    # Compute EBITDA
    ebitda_records = []
    all_months = sorted(set(rev_map.keys()) | set(opex_map.keys()))

    for m in all_months:
        if m in rev_map and m in opex_map:
            ebitda_records.append({
                "amount": rev_map[m] - opex_map[m],
                "ending_date_of_month": m
            })

    # Final usecases dict
    usecases = {
        "Revenue": revenue_l6,        # ✔ full L6 breakdown
        "OPEX": opex_l6_top3,         # ✔ top 3 L6 breakdown only
        "EBITDA": { "ebitda": ebitda_records }
    }

    return usecases



usecases = build_usecases_from_df(df_filtered)
usecases
