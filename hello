# Load your concatenated CSV file
concat_df = spark.read.csv("Files/SQL_DUMPS/FACTS_CONCAT_DEDUP_JOINED_KPI", header=True, inferSchema=True)

# Count total rows
total_rows = concat_df.count()
print(f"Total rows in concatenated file: {total_rows:,}")



concat_df.groupBy("FACT_SOURCE").count().show()
