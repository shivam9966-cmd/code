
subset_df = spark.read.csv("Files/SQL_DUMPS/FINAL_EXPORTS/Run_YYYY-MM-DD_HH-MM-SS/granular_subset", header=True, inferSchema=True)




subset_pd = subset_df.limit(50).toPandas()

display(subset_pd)


years_present = subset_df.select("YEAR").distinct().orderBy("YEAR")
years_present.show(truncate=False)
