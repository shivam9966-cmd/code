# Convert Spark to Pandas (be careful with size)
pdf = df_2426.toPandas()

output_path = "/lakehouse/default/Files/filtered_2024_2026_dump.sql"

with open(output_path, "w", encoding="utf-8") as f:
    for _, row in pdf.iterrows():
        cols = ", ".join(pdf.columns)
        vals = []
        for v in row.values:
            # Escape single quotes
            v = str(v).replace("'", "''")
            vals.append(f"'{v}'")
        vals = ", ".join(vals)
        f.write(f"INSERT INTO your_table_name ({cols}) VALUES ({vals});\n")

print("SQL dump written to:", output_path)
