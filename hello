import os
import json

# ============ AZURE OPENAI CONFIG (YOU WILL REPLACE XXX) ============
AZURE_OPENAI_API_KEY   = "XXX"   # your API key
AZURE_OPENAI_ENDPOINT  = "XXX"   # e.g., https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VER   = "XXX"   # e.g., 2024-10-01-preview

AZURE_LLM_DEPLOYMENT   = "XXX"   # your chat model deployment
AZURE_EMB_DEPLOYMENT   = "XXX"   # your embedding model deployment


# ============ LlamaIndex Setup ============

from llama_index.llms.azure_openai import AzureOpenAI
from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding
from llama_index.core import Settings


llm = AzureOpenAI(
    model=AZURE_LLM_DEPLOYMENT,
    deployment_name=AZURE_LLM_DEPLOYMENT,
    api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_version=AZURE_OPENAI_API_VER,
    temperature=0.1,
)

embed_model = AzureOpenAIEmbedding(
    model=AZURE_EMB_DEPLOYMENT,
    deployment_name=AZURE_EMB_DEPLOYMENT,
    api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_version=AZURE_OPENAI_API_VER,
)

# Register globally
Settings.llm = llm
Settings.embed_model = embed_model


# ============ JSON PARSER (SAFE) ============
def _parse_json_from_text(text: str) -> dict:
    """
    Safely extracts the JSON object from the LLM output.
    Handles ```json blocks and trims extra text.
    """
    if "```" in text:
        start = text.find("```")
        end = text.rfind("```")
        fenced = text[start + 3:end].strip()
        if fenced.lower().startswith("json"):
            fenced = fenced[4:].strip()
        text = fenced

    # keep only outermost {...}
    first = text.find("{")
    last = text.rfind("}")
    if first != -1 and last != -1 and last > first:
        text = text[first:last + 1]

    return json.loads(text)


# ============ MAIN FUNCTION ============

def generate_business_summary(usecases: dict) -> dict:
    """
    Generates a structured business summary using Azure OpenAI via LlamaIndex.
    Input: usecases dict (already containing all metrics)
    Output: structured JSON (Python dict)
    """

    # detect OPEX-only case
    keys_lower = {k.lower() for k in usecases.keys()}
    is_opex_only = (
        "opex" in keys_lower
        and "revenue" not in keys_lower
        and "ebitda" not in keys_lower
    )

    base_instructions = """
You are an FP&A expert. I am giving you a JSON object `usecases` that already 
contains all calculated monthly values for Revenue, OPEX and EBITDA.

Do NOT calculate new numbers.
Do NOT modify numbers.
ONLY interpret trends.

Language should be executive-level, concise, and business oriented.

You MUST return pure JSON. No text outside JSON.
"""

    opex_rule = """
Special rule:
This is an OPEX-only dataset.
Do NOT mention Revenue or EBITDA anywhere.
""" if is_opex_only else """
Special rule:
If OPEX exists, explain its link to EBITDA and business profitability.
"""

    json_structure = """
Return the result strictly in this JSON structure:

{
  "revenue_summary": "",
  "recurring_revenue_summary": "",
  "non_recurring_revenue_summary": "",
  "ps_revenue_summary": "",
  "opex_summary": "",
  "variable_expense_summary": "",
  "capitalized_costs_summary": "",
  "compensation_summary": "",
  "ebitda_summary": "",
  "key_risks": "",
  "key_opportunities": ""
}
"""

    # final prompt
    prompt = (
        base_instructions
        + opex_rule
        + json_structure
        + "\nHere is the `usecases` JSON:\n"
        + json.dumps(usecases, indent=2)
        + "\nRespond ONLY with JSON."
    )

    # LLM call
    response = llm.complete(prompt)
    text = response.text

    # parse clean JSON
    output_dict = _parse_json_from_text(text)

    return output_dict













summary = generate_business_summary(usecases)

summary
