from pyspark.sql import functions as F

rename_map = {
    "product_L3_Description": "product_L3_Description",
    "product_L4_Description": "product_L4_Description",
    "product_L5_Description": "product_L5_Description",
    "product_L6_Description": "product_L6_Description",
    "product_L7_Description": "product_L7_Description",
    "product_L8_Description": "product_L8_Description",

    "account_L4_Description": "account_L4_Description",
    "account_L5_Description": "account_L5_Description",
    "account_L6_Description": "account_L6_Description",
    "account_L7_Description": "account_L7_Description",

    "CC_L1_Description": "CC_L1_Description",
    "CC_L2_Description": "CC_L2_Description",
    "CC_L3_Description": "CC_L3_Description",
    "CC_L4_Description": "CC_L4_Description",

    # FACT columns â†’ lowercase names
    "ACCOUNT": "account",
    "COSTCENTER": "costcenter",
    "PRODUCTLINE": "productline",
    "SCENARIO": "scenario",
    "VERSION": "version",
    "Amount": "amount",
    "YEAR": "year",
    "QUARTER": "quarter",
    "DATE": "date",

    # Month fields
    "Actual": "actual_months",
    "Forecasted": "forecasted_months"
}

df_final = df_2426
for old, new in rename_map.items():
    if old in df_final.columns:
        df_final = df_final.withColumnRenamed(old, new)

# Replace nulls in month columns
df_final = df_final.fillna({
    "actual_months": 0,
    "forecasted_months": 0
})

df_final.select(*rename_map.values()).show(5)
print("Final columns:", df_final.columns)
