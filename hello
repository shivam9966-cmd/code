import pandas as pd
from sqlalchemy import create_engine

# ----------------------------
# DATABASE DETAILS
# ----------------------------
DB_USER = "postgres"
DB_PASSWORD = "postgres"          # as requested
DB_HOST = "localhost"             # change if not local
DB_PORT = 5432
DB_NAME = "your_database_name"    # ðŸ‘ˆ change this

SCHEMA = "finance"
TABLE_NAME = "kpi_data_new"       # NEW table name
CSV_PATH = r"C:\path\to\your_file.csv"   # ðŸ‘ˆ change this

# ----------------------------
# CREATE CONNECTION
# ----------------------------
engine = create_engine(
    f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
)

# ----------------------------
# READ CSV
# ----------------------------
df = pd.read_csv(CSV_PATH)

print("CSV columns found:")
print(df.columns.tolist())

# ----------------------------
# KEEP ONLY REQUIRED COLUMNS
# (extra CSV columns are ignored safely)
# ----------------------------
required_columns = [
    "account",
    "costcenter",
    "productline",
    "scenario",
    "version",
    "year",
    "date",                       # maps to month in API
    "amount",
    "account_L5_Description",
    "account_L6_Description",
]

df = df[[c for c in required_columns if c in df.columns]]

# ----------------------------
# UPLOAD TO POSTGRES
# ----------------------------
df.to_sql(
    TABLE_NAME,
    engine,
    schema=SCHEMA,
    if_exists="replace",   # use "append" if table already exists
    index=False
)

print(f"âœ… Upload complete â†’ {SCHEMA}.{TABLE_NAME}")
