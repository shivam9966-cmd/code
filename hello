

import pyspark.sql.functions as F

# ---- Load facts & dimensions ----
actual_df   = spark.table("FPNA_FISRPT_SILVER.dbo.ACTUALS")
plan_df     = spark.table("FPNA_FISRPT_SILVER.dbo.PLAN")
forecast_df = spark.table("FPNA_FISRPT_SILVER.dbo.FORECAST")

account_df    = spark.table("FPNA_FISRPT_SILVER.dbo.account")       # key: Account
product_df    = spark.table("FPNA_FISRPT_SILVER.dbo.product")       # key: ProductLine
costcenter_df = spark.table("FPNA_FISRPT_SILVER.dbo.cost_center")   # key: COSTCENTER  (as you said)

# ---- helper: locate 'Amount' column (case-insensitive) ----
def amount_col(df):
    for c in df.columns:
        if c.lower() == "amount":
            return c
    raise ValueError("No 'Amount' column found (case-insensitive).")

# ---- Build one KPI-scoped, joined fact with prefixes & FACT_SOURCE ----
def build_fact(fact_df, source_name):
    d  = fact_df.alias("d")
    ad = account_df.alias("ad")
    pd = product_df.alias("pd")
    cc = costcenter_df.alias("cc")

    # join to bring hierarchies (no filtering yet)
    j = (
        d.join(ad, F.col("d.ACCOUNT")     == F.col("ad.Account"),     "left")
         .join(pd, F.col("d.PRODUCTLINE") == F.col("pd.ProductLine"), "left")
         .join(cc, F.col("d.COSTCENTER")  == F.col("cc.COSTCENTER"),  "left")
    )

    # KPI tagging from account hierarchy (exactly as you wanted)
    j = j.withColumn(
        "KPI",
        F.when(F.col("ad.L5_Description") == "Revenue", "Revenue")
         .when(F.col("ad.L5_Description") == "Operating Expenses", "OPEX")
         .when(F.col("ad.L4") == "EBITDA", "EBITDA")
    ).filter(F.col("KPI").isNotNull())

    # keep fact cols as-is
    fact_cols = [F.col(f"d.{c}").alias(c) for c in fact_df.columns]

    # prefix all dim columns so nothing collides
    acc_cols  = [F.col(f"ad.{c}").alias(f"acc_{c}")  for c in account_df.columns]
    prod_cols = [F.col(f"pd.{c}").alias(f"prod_{c}") for c in product_df.columns]
    cc_cols   = [F.col(f"cc.{c}").alias(f"cc_{c}")   for c in costcenter_df.columns]

    out = (
        j.select(*(fact_cols + acc_cols + prod_cols + cc_cols + [F.col("KPI")]))
         .withColumn("FACT_SOURCE", F.lit(source_name))
    )
    return out

gran_act   = build_fact(actual_df,   "ACTUALS")
gran_plan  = build_fact(plan_df,     "PLAN")
gran_fcst  = build_fact(forecast_df, "FORECAST")

# ---- Stack all three (by column name) ----
gran_all = (
    gran_act
      .unionByName(gran_plan, allowMissingColumns=True)
      .unionByName(gran_fcst, allowMissingColumns=True)
)

# ---- STRICT de-duplication:
# group by *all* columns except Amount; sum Amount inside identical rows only
amt = amount_col(gran_all)
group_keys = [c for c in gran_all.columns if c != amt]  # this includes SCENARIO/YEAR/VERSION, FACT_SOURCE, and all prefixed dims

granular_strict = gran_all.groupBy(group_keys).agg(F.sum(F.col(amt)).alias(amt))

# ---- (Optional) quick sanity: counts per source
print("Row counts by FACT_SOURCE (after strict dedupe):")
granular_strict.groupBy("FACT_SOURCE").count().orderBy("FACT_SOURCE").show(truncate=False)

# If you want to SAVE it:
# granular_strict.coalesce(1).write.mode("overwrite").parquet("Files/SQL_DUMPS/GRANULAR_STRICT_KPI")
