from pyspark.sql import functions as F

# --------------------------
# Helper: Add Quarter Column
# --------------------------
def add_quarter(df):
    return df.withColumn(
        "QUARTER",
        F.when(F.month("DATE").between(1,3),  "Q1")
         .when(F.month("DATE").between(4,6),  "Q2")
         .when(F.month("DATE").between(7,9),  "Q3")
         .otherwise("Q4")
    )

# ----------------------------------------
# Helper: Filter dataset by KPI + Scenario
# ----------------------------------------
def get_filtered(df, amount_type, scenario, version):
    cond_kpi = F.col("KPI") == amount_type
    cond_scenario = F.col("SCENARIO") == scenario
    cond_version  = F.col("VERSION") == version
    cond_year     = F.col("YEAR") == 2025

    df_f = df.filter(cond_kpi & cond_scenario & cond_version & cond_year)
    df_f = add_quarter(df_f)

    return df_f

# -----------------------------------------------------
# Main Function: Quarter-Wise Variance for a KPI
# -----------------------------------------------------
def variance_quarter_kpi(df, amount_type):
    
    # Scenario 1 → FY25 Plan Final
    s1 = get_filtered(
        df,
        amount_type=amount_type,
        scenario="PLAN",
        version="Final"
    )

    # Scenario 2 → FY25 F7_5 At Plan Rates
    s2 = get_filtered(
        df,
        amount_type=amount_type,
        scenario="F7_5",
        version="At_Plan_Rates"
    )

    # ------------------------------------
    # Aggregate by Account + Quarter + Total
    # ------------------------------------
    agg_s1 = (
        s1.groupBy("account_L6_Description", "QUARTER")
          .agg(F.sum("Amount").alias("S1"))
    )

    agg_s2 = (
        s2.groupBy("account_L6_Description", "QUARTER")
          .agg(F.sum("Amount").alias("S2"))
    )

    # Join scenario1 & scenario2
    joined = (
        agg_s1.join(
            agg_s2,
            ["account_L6_Description", "QUARTER"],
            "full"
        )
    )

    # ----------------------------
    # Pivot to Q1–Q4 format
    # ----------------------------
    pivot_df = (
        joined.groupBy("account_L6_Description")
              .pivot("QUARTER", ["Q1","Q2","Q3","Q4"])
              .agg(F.first("S1").alias("S1"), F.first("S2").alias("S2"))
    )

    # ----------------------------
    # Compute totals
    # ----------------------------
    pivot_df = pivot_df.withColumn(
        "S1_Total",
        sum(F.col(f"{q}_S1") for q in ["Q1","Q2","Q3","Q4"])
    ).withColumn(
        "S2_Total",
        sum(F.col(f"{q}_S2") for q in ["Q1","Q2","Q3","Q4"])
    )

    # ----------------------------
    # Variance + Variance %
    # ----------------------------
    pivot_df = pivot_df.withColumn(
        "Variance",
        F.col("S2_Total") - F.col("S1_Total")
    ).withColumn(
        "Variance%",
        (F.col("Variance") / F.col("S1_Total")) * 100
    )

    return pivot_df

# -------------------------------
# Run for Revenue / OPEX / EBITDA
# -------------------------------
revenue_var_df = variance_quarter_kpi(granular, "Revenue")
opex_var_df    = variance_quarter_kpi(granular, "Operating Expenses")
ebitda_var_df  = variance_quarter_kpi(granular, "EBITDA")

# Show or convert to pandas
revenue_var_df.show(truncate=False)
opex_var_df.show(truncate=False)
ebitda_var_df.show(truncate=False)
