# ============================================================
# Unified Granular Join (Actuals + Plan + Forecast)
# - Step 1: Surface duplicates (views) and pause
# - Step 2: (toggle RUN_BUILD=True) Dedupe + Join + Filter + Union
# ============================================================

import pyspark.sql.functions as F
from functools import reduce

# -----------------------------
# Controls (read these first)
# -----------------------------
RUN_BUILD       = False                 # (1) Start with False to only create duplicate views
FILTER_YEARS    = ["FY25"]              # (6) Year filter
FILTER_SCENARIO = None                  # (4) e.g., ["PLAN","F7_5"] or None
FILTER_VERSION  = None                  # (4) e.g., ["Final","At_Plan_Rates"] or None
KEEP_ONLY_KPI   = True                  # Keep only Revenue / Operating Expenses / EBITDA
EBITDA_CODES    = []                    # (5) Optional explicit account codes for EBITDA (e.g., ["EBITDA_TOTAL","400000"])

# -----------------------------
# Load your 6 base tables
# -----------------------------
actual_df   = spark.table("FPNA_FISRPT_SILVER.dbo.ACTUALS")
plan_df     = spark.table("FPNA_FISRPT_SILVER.dbo.PLAN")
forecast_df = spark.table("FPNA_FISRPT_SILVER.dbo.FORECAST")

account_df    = spark.table("FPNA_FISRPT_SILVER.dbo.account")
product_df    = spark.table("FPNA_FISRPT_SILVER.dbo.product")
costcenter_df = spark.table("FPNA_FISRPT_SILVER.dbo.cost_center")

# -----------------------------
# Helpers
# -----------------------------
def cols_except(df, exclude):
    ex = set(exclude)
    return [c for c in df.columns if c not in ex]

def find_duplicates(df, fact_name):
    """(1) Build two duplicate views: exact dupes; and 'only Amount differs' groups."""
    exact = (
        df.groupBy(df.columns).count()
          .filter(F.col("count") > 1)
          .withColumn("FACT_SOURCE", F.lit(fact_name))
    )
    keys_wo_amt = cols_except(df, ["Amount"])
    amount_only = (
        df.groupBy(keys_wo_amt)
          .agg(
              F.count(F.lit(1)).alias("row_count"),
              F.countDistinct("Amount").alias("amount_variants"),
              F.sum("Amount").alias("summed_amount_for_key")
          )
          .filter(F.col("amount_variants") > 1)
          .withColumn("FACT_SOURCE", F.lit(fact_name))
    )
    exact.createOrReplaceTempView(f"vw_exact_dups_{fact_name.lower()}")
    amount_only.createOrReplaceTempView(f"vw_amount_only_dups_{fact_name.lower()}")

def dedupe_sum_amount(df):
    """(2) If only Amount differs, sum it (group by all non-Amount columns)."""
    keys_wo_amt = cols_except(df, ["Amount"])
    return df.groupBy(keys_wo_amt).agg(F.sum("Amount").alias("Amount"))

def contains_any(substr, qualified_cols):
    expr = None
    for qc in qualified_cols:
        cexpr = F.upper(F.col(qc)).contains(substr)
        expr = cexpr if expr is None else (expr | cexpr)
    return expr if expr is not None else F.lit(False)

# -----------------------------
# Build joined granular for one fact (3,4,5,6,7,8)
# -----------------------------
def build_granular_for_fact(fact_df, fact_name, scenarios=None, years=None, versions=None):
    # (2) Deduplicate by Amount rule
    a = dedupe_sum_amount(fact_df).alias("a")

    # Aliased dims
    ad = account_df.alias("ad")
    pd = product_df.alias("pd")
    cc = costcenter_df.alias("cc")

    # (3 & 8) Join dims (left) â€” keep fact columns intact, dims will be prefixed
    j = (
        a.join(ad, F.col("a.ACCOUNT")     == F.col("ad.Account"),     "left")
         .join(pd, F.col("a.PRODUCTLINE") == F.col("pd.ProductLine"), "left")
         .join(cc, F.col("a.COSTCENTER")  == F.col("cc.CostCenter"),  "left")
    )

    # (4 & 6) Only SCENARIO / YEAR / VERSION filters (no conversions)
    conds = []
    if scenarios: conds.append(F.col("a.SCENARIO").isin([*scenarios]))
    if years:     conds.append(F.col("a.YEAR").isin([*years]))
    if versions:  conds.append(F.col("a.VERSION").isin([*versions]))
    if conds:
        j = j.filter(reduce(lambda x, y: x & y, conds))

    # (5) KPI tagging: Revenue / OpEx via L5_Description (if present), EBITDA via L4 == 'EBITDA' or explicit codes
    ad_cols = set(account_df.columns)
    has_L4      = "L4" in ad_cols
    has_L5_desc = "L5_Description" in ad_cols
    has_acc     = "Account" in ad_cols
    has_desc    = "Description" in ad_cols

    revenue_expr = (F.col("ad.L5_Description") == "Revenue") if has_L5_desc \
                   else contains_any("REVENUE", ["ad.Description"] if has_desc else [])
    opex_expr    = (F.col("ad.L5_Description") == "Operating Expenses") if has_L5_desc \
                   else contains_any("OPERATING EXPENSE", ["ad.Description"] if has_desc else [])
    ebitda_expr  = ((F.col("ad.L4") == "EBITDA") if has_L4 else F.lit(False)) | \
                   ((F.col("ad.Account").isin(EBITDA_CODES)) if (has_acc and EBITDA_CODES) else F.lit(False))

    if KEEP_ONLY_KPI:
        j = j.withColumn(
            "KPI",
            F.when(revenue_expr, "Revenue")
             .when(opex_expr, "Operating Expenses")
             .when(ebitda_expr, "EBITDA")
        ).filter(F.col("KPI").isNotNull())
    else:
        j = j.withColumn("KPI", F.lit(None).cast("string"))

    # (8) Project all columns:
    # - Fact columns unchanged
    fact_cols = [F.col(f"a.{c}").alias(c) for c in fact_df.columns]

    # - Dimension columns with prefixes to avoid name clashes (acc_, prod_, cc_)
    acc_cols  = [F.col(f"ad.{c}").alias(f"acc_{c}")  for c in account_df.columns]
    prod_cols = [F.col(f"pd.{c}").alias(f"prod_{c}") for c in product_df.columns]
    cc_cols   = [F.col(f"cc.{c}").alias(f"cc_{c}")   for c in costcenter_df.columns]

    out = j.select(*(fact_cols + acc_cols + prod_cols + cc_cols)) \
           .withColumn("FACT_SOURCE", F.lit(fact_name))
    return out

# -----------------------------
# (1) Create duplicate views first, then pause here unless RUN_BUILD=True
# -----------------------------
find_duplicates(actual_df,   "ACTUALS")
find_duplicates(plan_df,     "PLAN")
find_duplicates(forecast_df, "FORECAST")
print("[INFO] Duplicate views created: vw_exact_dups_actuals/plan/forecast and vw_amount_only_dups_*")

if not RUN_BUILD:
    print("[PAUSED] Review duplicate views. Set RUN_BUILD=True to proceed with join+dedupe.")
else:
    # -------------------------
    # Build per fact with filters (SCENARIO/YEAR/VERSION only)
    # -------------------------
    gran_actual   = build_granular_for_fact(actual_df,   "ACTUALS",
                                            scenarios=FILTER_SCENARIO, years=FILTER_YEARS, versions=FILTER_VERSION)
    gran_plan     = build_granular_for_fact(plan_df,     "PLAN",
                                            scenarios=FILTER_SCENARIO, years=FILTER_YEARS, versions=FILTER_VERSION)
    gran_forecast = build_granular_for_fact(forecast_df, "FORECAST",
                                            scenarios=FILTER_SCENARIO, years=FILTER_YEARS, versions=FILTER_VERSION)

    # (3) One file (single unified DF). Keeping rows from all facts (no cross-fact collapsing).
    granular_all = (
        gran_actual
          .unionByName(gran_plan, allowMissingColumns=True)
          .unionByName(gran_forecast, allowMissingColumns=True)
    )

    # Quick peek to confirm
    granular_all.select(
        "FACT_SOURCE", "ACCOUNT", "COSTCENTER", "PRODUCTLINE", "Amount",
        "acc_L4", "acc_L5_Description", "prod_L4_Description", "cc_L4_Description", "KPI", "YEAR", "SCENARIO", "VERSION"
    ).show(20, truncate=False)

    print("[OK] Unified granular dataset is ready in variable: granular_all")
